{
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Fork of Saudi cars Prediction",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2395181,
          "sourceType": "datasetVersion",
          "datasetId": 1430609
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussainqadiim/-/blob/main/Fork_of_Saudi_cars_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'saudi-arabia-used-cars-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1430609%2F2395181%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240215%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240215T145254Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3472fee4f31abbe9773f9749fefc94c8c5da915bd434b518af45aa1a433847f87f1b37bf310daff9b651bffaf4001099c939dd959a221687e205e404494b706168d0f8c22f807eeada43a3d611c0a24fc363b74ad8321116cbbbf3ec03a047f2d7614abedd4ce925985b86804c55e19e9ad0a00ac1ba7d6ad28be9df97629217880fff6d88c7ef06bf2d20d8536fb2b8da93d7c603c5629cf06a949c8334cb299e16b36a10f08c921532947662082a9fcd1f456a28d2ae163dc0842081e32ce069af6d7eb338fdbf6226c898eea021ad7049a79cb079075033b9cd7a11c52805a216e8a91d5f429a8f427ba6d0d71eb0afee856a407f6c84994cd1229ec9bb67'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Sh4alQ-JQZ2F"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Importing Modules and Predefined Functions**"
      ],
      "metadata": {
        "id": "-6iIjdT2_54i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, LabelEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from yellowbrick.regressor import PredictionError\n",
        "from yellowbrick.features import RadViz\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (7,4)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "#pd.set_option('display.width', 1000)\n",
        "#pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ],
      "metadata": {
        "id": "8nSvROeM02LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connecting to Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mIZWsSI81Fv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/saudi-arabia-used-cars-dataset/UsedCarsSA_Clean_EN.csv')\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "5Ouwj3fN1F6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Sv8clxD-1GAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values in the DataFrame 'df' and calculating the count of null values per column\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "c4AO1_ij1GHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Cleaning & Exploratory Data Analysis**\n",
        "\n"
      ],
      "metadata": {
        "id": "7qpnFpa7AEQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the 'Type' values that occur 50 times or less in the DataFrame 'df'\n",
        "# and store these values' indices in 'drop_model'\n",
        "\n",
        "drop_model = df.Type.value_counts()[df.Type.value_counts() <= 50].index\n",
        "drop_model\n"
      ],
      "metadata": {
        "id": "ZVwQYoLV1GPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For each value 'i' in 'drop_model':\n",
        "for i in drop_model:\n",
        "    # Find the indices where the 'Type' column in the DataFrame 'df' matches the value 'i'\n",
        "    drop_index = df[df['Type'] == i].index\n",
        "\n",
        "    # Drop rows from 'df' based on the found indices\n",
        "    df.drop(index=drop_index, inplace=True)\n",
        "\n",
        "# Reset the indices of 'df' after dropping rows and make the changes permanent\n",
        "df.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "id": "ivIEv9cfcCgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Type.value_counts()"
      ],
      "metadata": {
        "id": "7qm30bY7cCsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns with data type 'object' from the DataFrame 'df' and retrieve the first few rows\n",
        "\n",
        "df_object = df.select_dtypes(include =\"object\").head()\n",
        "df_object"
      ],
      "metadata": {
        "id": "lgDQdhI3cC6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_object:\n",
        "    # Print the column name and the number of unique values in the corresponding column in the original DataFrame 'df'\n",
        "    print(f\"{col:<30}:\", df[col].nunique())"
      ],
      "metadata": {
        "id": "1n1und7LdcrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "0nsc0tokYIwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop specific columns\n",
        "\n",
        "df.drop([\"Make\",\"Origin\",\"Color\",\"Engine_Size\",\"Gear_Type\",\"Fuel_Type\",\"Region\",\"Negotiable\"], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "E4-9BPc41GWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "KQoNbukW4V-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the DataFrame 'df' to show rows where the 'Price' column has a value of 0\n",
        "\n",
        "df[df.Price == 0]"
      ],
      "metadata": {
        "id": "e25A0eVC1GdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame 'df' to exclude rows where the 'Price' column equals 0\n",
        "df = df[df['Price'] != 0]\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "BQ6uKlJi1Gjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "uNdoKWmr1IVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the DataFrame 'df' based on the 'Price' column in ascending order\n",
        "\n",
        "df.sort_values(by='Price', ascending=1, inplace=True)\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "3eqVD7SX1Jv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the Price less than 5000\n",
        "df = df[df['Price'] > 5000]\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "ynP9SQrh1J5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df.Price > 170000])"
      ],
      "metadata": {
        "id": "1DAEawpxrJS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the Price more than 170000\n",
        "df = df[df.Price < 170000]\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "1qbtEWIgm1jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5CkQ2t-frAvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop Mileage more than 700000\n",
        "df = df[df['Mileage'] < 700000]\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "bih2Ou6-1KBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "YW_fLNO-1KLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Visualization**"
      ],
      "metadata": {
        "id": "jePHKaN_Ago6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.select_dtypes(include='number').corr(), annot=True, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ew3KxZOs1KS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = df.Type.value_counts().iloc[:35].plot(kind =\"bar\", figsize=(20,5))\n",
        "\n",
        "ax.bar_label(ax.containers[0]);\n",
        "\n",
        "# we see the top models with the most observations in our data and their numbers."
      ],
      "metadata": {
        "id": "eoIdJIbVtlgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the age of vehicles by subtracting the 'Year' column values from 2023\n",
        "df[\"vehicle_age\"]=2023-df.Year"
      ],
      "metadata": {
        "id": "a5shOdBN50gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "zeyy7Uwo50tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'Year' column from the DataFrame 'df' along the columns axis\n",
        "df.drop(\"Year\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "mqO7Ejqk51NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "e_87w-wT6zHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select_dtypes(\"object\").head()"
      ],
      "metadata": {
        "id": "mpDd32qK504C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.select_dtypes(\"object\"):\n",
        "\n",
        "    print(i, len(df[i].value_counts()))"
      ],
      "metadata": {
        "id": "ZMEe1cOq51DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7cOUsuQ7zmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data"
      ],
      "metadata": {
        "id": "h7xnNam8A0GZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(\"Price\", axis=1)\n",
        "y=df.Price"
      ],
      "metadata": {
        "id": "ipUBsXOm51XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=5)\n",
        "\n",
        "print(\"Train features shape : \", X_train.shape)\n",
        "print(\"Train target shape   : \", y_train.shape)\n",
        "print(\"Test features shape  : \", X_test.shape)\n",
        "print(\"Test target shape    : \", y_test.shape)"
      ],
      "metadata": {
        "id": "qQRUnqnP51gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat = X.select_dtypes(\"object\").columns\n",
        "cat"
      ],
      "metadata": {
        "id": "-r-xXjIy51pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "column_trans = make_column_transformer(\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat),\n",
        "    remainder=MinMaxScaler(),\n",
        "    verbose_feature_names_out=False,\n",
        ")"
      ],
      "metadata": {
        "id": "OhbfJkjj51y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df.Price, bins=100, kde=True);"
      ],
      "metadata": {
        "id": "azVmtTFkIKnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_outliers = []\n",
        "\n",
        "for model in df.Type.unique():\n",
        "\n",
        "    car_prices = df[df[\"Type\"]== model][\"Price\"]\n",
        "\n",
        "    Q1 = car_prices.quantile(0.25)\n",
        "    Q3 = car_prices.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_lim = Q1 - 1.5*IQR\n",
        "    upper_lim = Q3 + 1.5*IQR\n",
        "\n",
        "    count_of_outliers = (car_prices[(car_prices < lower_lim) | (car_prices > upper_lim)]).count()\n",
        "\n",
        "    total_outliers.append(count_of_outliers)\n",
        "\n",
        "    print(f\" The count of outlier for {model:<24} : {count_of_outliers:<2},\\\n",
        "    The rate of outliers : {(count_of_outliers/len(df[df['Type']== model])).round(3)}\")\n",
        "print()\n",
        "print(\"Total_outliers : \",sum(total_outliers), \"The rate of total outliers :\", (sum(total_outliers)/len(df)).round(3))"
      ],
      "metadata": {
        "id": "IsuRe-0Wd_AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "xYTXZE3mixK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRFw8lsvjEKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Duplicated Rows : ', df.duplicated().sum())"
      ],
      "metadata": {
        "id": "kCXaI3SlWSlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "c7-_s_4cW8RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Remaining Duplicated Rows:', df.duplicated().sum())"
      ],
      "metadata": {
        "id": "xMQl_BvpW8au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Missing Value   : ', df.isna().sum().sum())"
      ],
      "metadata": {
        "id": "emYOroRtWSxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "sns.boxplot(x=df['Price'])\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ErYRg8eWS6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJeIqX7gkGuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "5ZyvpP0-GFZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_onehot = ['Type']\n",
        "\n",
        "cat_ordinal = ['Options']\n",
        "cat_for_Options = [\"Standard\" , \"Semi Full\" ,\"Full\"]"
      ],
      "metadata": {
        "id": "cCsrgdnpd_OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Options'].unique()"
      ],
      "metadata": {
        "id": "dqP7wyWrgzw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming cat_onehot, cat_ordinal, and cat_for_Options are defined elsewhere\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "column_trans = make_column_transformer(\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\", sparse=False), cat_onehot),\n",
        "    (OrdinalEncoder(categories=[cat_for_Options]), cat_ordinal),\n",
        "    (scaler, ['Mileage', 'vehicle_age']),\n",
        "    remainder='passthrough',\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "# Setting output transformation to pandas dataframe\n",
        "column_trans = column_trans.set_output(transform=\"pandas\")\n"
      ],
      "metadata": {
        "id": "VWNEk5Olgz-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_trans.fit_transform(X_train).head()"
      ],
      "metadata": {
        "id": "b774fPEzg0gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_trans = column_trans.fit_transform(X_train)\n",
        "X_test_trans = column_trans.transform(X_test)"
      ],
      "metadata": {
        "id": "1O2V7VfFjDkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_trans.shape, X_test_trans.shape"
      ],
      "metadata": {
        "id": "H3sVjUBWjD0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_trans.join(y_train).corr()"
      ],
      "metadata": {
        "id": "MFaC9x6vjD-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "09ovFFU4BJ_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val(model, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    scores = {\"train\": {\"R2\" : r2_score(y_train, y_train_pred),\n",
        "                        \"mae\" : mean_absolute_error(y_train, y_train_pred),\n",
        "                        \"mse\" : mean_squared_error(y_train, y_train_pred),\n",
        "                        \"rmse\" : mean_squared_error(y_train, y_train_pred, squared=False)},\n",
        "              \"test\": {\"R2\" : r2_score(y_test, y_pred),\n",
        "                       \"mae\" : mean_absolute_error(y_test, y_pred),\n",
        "                       \"mse\" : mean_squared_error(y_test, y_pred),\n",
        "                       \"rmse\" : mean_squared_error(y_test, y_pred, squared=False)}}\n",
        "\n",
        "    return pd.DataFrame(scores)"
      ],
      "metadata": {
        "id": "G-q3tFQzj1m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "LR_model = LinearRegression()\n",
        "operations = [(\"preprocess\", column_trans),\n",
        "              (\"Linear\", LinearRegression())]\n",
        "\n",
        "LR_pipeline = Pipeline(steps=operations)\n",
        "LR_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = LR_pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "ZRxquVZwJjk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val(LR_pipeline, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "46Sfd-qhJjxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "visualizer = RadViz(size=(720, 600))\n",
        "\n",
        "LR_model = LR_pipeline\n",
        "visualizer = PredictionError(LR_pipeline)\n",
        "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "visualizer.show();"
      ],
      "metadata": {
        "id": "8ss4AVfcTXqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "operations = [(\"preprocess\", column_trans), (\"Lasso\", Lasso())]\n",
        "\n",
        "lasso_model = Pipeline(steps=operations)\n",
        "\n",
        "lasso_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3Y0nakGu4R4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val(lasso_model, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "s5d4H7oK4SCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "id": "f8GTBbxSBRel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "xgb_model = XGBRegressor()\n",
        "\n",
        "operations = [(\"preprocess\", column_trans),('xgb_model', xgb_model) ]\n",
        "\n",
        "XGB_pipeline = Pipeline(steps=operations)\n",
        "\n",
        "XGB_pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RAJgDcJqJkNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val(XGB_pipeline, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "0DmNpVp3DiPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "RF_model = RandomForestRegressor()\n",
        "\n",
        "operations = [(\"preprocess\", column_trans),(\"RF_model\", RandomForestRegressor(random_state=101)) ]\n",
        "\n",
        "RF_pipeline = Pipeline(steps=operations)\n",
        "\n",
        "RF_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6JvWKKzppPZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val(RF_pipeline, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "kNLeqlEVbrv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "visualizer = RadViz(size=(720, 600))\n",
        "\n",
        "RF_model = RF_pipeline\n",
        "visualizer = PredictionError(RF_model)\n",
        "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "visualizer.show(); # Values bigger than 300000 effect our predictions."
      ],
      "metadata": {
        "id": "pRf4jVB-52bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Prediction"
      ],
      "metadata": {
        "id": "GZuP7KKTBYw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = df[df.Price < 200000]\n",
        "df_new.head()"
      ],
      "metadata": {
        "id": "LVdYByO_52q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_new.drop(columns=\"Price\")\n",
        "y = df_new.Price"
      ],
      "metadata": {
        "id": "Vk7YuA98CHdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
      ],
      "metadata": {
        "id": "oiJ_rHMmCHmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming XGB_pipeline is your trained XGBoost pipeline\n",
        "LR_model = 'LR_model.pkl'\n",
        "\n",
        "with open(LR_model, 'wb') as file:\n",
        "    pickle.dump(LR_pipeline, file)\n"
      ],
      "metadata": {
        "id": "RKg_NfU5yfVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Type': ['Camry', 'Tahoe', 'Hilux'],\n",
        "    'Options': ['Full', 'Standard', 'Full'],\n",
        "    'Mileage': [125000 , 81833 , 190000],\n",
        "    'vehicle_age': [4 , 4 , 3]\n",
        "\n",
        "}\n",
        "\n",
        "new_test_data = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "fp-OJc7eLu8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LG_model\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Load the saved model\n",
        "LR_model = 'LR_model.pkl'\n",
        "\n",
        "with open(LR_model, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n"
      ],
      "metadata": {
        "id": "oARsRLLpdoKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = loaded_model.predict(new_test_data)\n",
        "\n",
        "# Print the predicted prices\n",
        "print(\"Predicted Prices:\")\n",
        "for prediction in predictions:\n",
        "    print(prediction)"
      ],
      "metadata": {
        "id": "7AGB1gFkLvNp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}